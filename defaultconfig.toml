inference_model_path = "C:/Users/Janal/.lmstudio/models/Jinx-org/Jinx-gpt-oss-20b-GGUF/jinx-gpt-oss-20b-mxfp4.gguf"

[database]
# Update these values to match your PostgreSQL installation
# Format: postgresql+asyncpg://user:password@host:port/database_name
url = "postgresql+asyncpg://postgres.tybtptkdxyfdhvwhpeub:stria-lm@aws-1-eu-north-1.pooler.supabase.com:5432/postgres"

[embedding]
default_model = "local_default"

[inference]
default_host = "127.0.0.1"
default_port = 8008
gguf_extensions = [ "*.gguf",]
inference_model_name = "default-model"
inference_model_path = ""

[embedding.models.local_default]
category = "Local"
model = "sentence-transformers/all-MiniLM-L6-v2"

[embedding.models.openai_default]
category = "OpenAI API"
model = "text-embedding-ada-002"
base_url = "https://api.openai.com/v1"
api_key = "YOUR_OPENAI_API_KEY"
